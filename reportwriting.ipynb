{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "\n",
    "## 4.3 Principal Component Analysis\n",
    "Principal component analysis simplifies the complexity of high-dimensional data by geometrically projecting them onto lower dimensions\n",
    "called principal components (PCs) while preserving as much of the data's variation as possible (Lever, 2017).\n",
    "These principal components are eigenvectors of the data's covariance matrix and often computed by\n",
    "eigendecomposition of the data covariance matrix. (Hedge, A. 2006)\n",
    "\n",
    "PCA essentially rotates the set of points around their mean in order to align them with the principal components.\n",
    "This moves as much of the variance as possible into the first few dimensions. The values in the remaining dimensions,\n",
    "therefore, tend to be small and may be dropped with minimal loss of information. (Jolliffe, I. 2016)\n",
    "\n",
    "We perform the PCA as part of our pre-processing. By retaining a selected number of PCs that together explain 95% of the variance of the\n",
    "image, we aim to reduce noise and increase contrast of the original image.\n",
    "Therewith we hope to improve the quality of the SVMs segmentation.\n",
    "\n",
    "After selecting the PCs, the image is uptransformed to its initial size.\n",
    "\n",
    "Because SVM is an algorithm that requires its features to be normalized, the PCA is performed with StandardScaler applied.\n",
    "This function scales the features to have zero as the mean and a standard deviaton of 1, to give\n",
    "it the feel and the properties of a standard normal distribution. As a positive side effect this also refines the SVMs prediction accuracy.\n",
    "\n",
    "# 5. Data Reduction\n",
    "As the images in our dataset consist of more than one million pixels each, running the SVM would take a lot of computational power and runtime.\n",
    "To decrease both, data reduction should be performed beforehand.\n",
    "The two possibilities we thought of, are resize form skimage and cutting the image into tiles before averaging over each tile.\n",
    "\n",
    "Resize from skimage cuts the image into a pre-defined scaling factor. We cut all images to 250 x 250.\n",
    "\n",
    "## 5.2 Tiles\n",
    "While PCA reduces data specifically, tiles-rendering is a simple approach that reduces data unspecifically by\n",
    "exploiting the fundamental properties of a problem space.\n",
    "The concept behind tiles is to save computational power, by splitting the image into multiple sets of N x N tiles\n",
    "and then calculate the average of each tile. The average intensity value of a specific tile is assigned to all pixels, belonging to\n",
    "this tile. Lastly, all tiles are reassembled to form the resulting image. (Rastar, A. 2019)\n",
    "\n",
    "As our tiles algorithm reduced the images quality in large measure, we decided to not use it as part of our algorithm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}