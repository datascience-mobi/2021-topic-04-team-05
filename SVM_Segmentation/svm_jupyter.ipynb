{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# SVM segmentation from VISUAL information only"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from skimage import feature\n",
    "from sklearn.svm import SVC\n",
    "import skimage as si\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "from sklearn.metrics import f1_score\n",
    "from skimage.feature import multiscale_basic_features, canny\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.exposure import adjust_log\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "imgs = glob(\"../Data/N2DH-GOWT1/img/*.tif\")\n",
    "masks = glob(\"../Data/N2DH-GOWT1/gt/tif/*\")\n",
    "IMG_SIZE = 250\n",
    "print(f\"Using {IMG_SIZE} of image size\")\n",
    "print(f\"We have {len(imgs)} with {len(masks)} masks\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using pixel intensity only\n",
    "\n",
    "This is a first approach to solve this, in this case we will generate a features matrix with the shape (Number_of_pixels, 1), since the original images are too big to do quick testing, I suggest to resize them, you can use the parameter IMG_SIZE to do just that.\n",
    "\n",
    "$$ X = N_{pixels} \\times 1$$\n",
    "$$W = 1 \\times 1$$\n",
    "$$Y = N_{pixels} \\times 1$$\n",
    "\n",
    "Remember that $N_{pixels}$ is the total amount of pixels that are in the training data, in this case two images of IMG_SIZE, $$N_{pixels} = \\operatorname{N of images}\\times(\\operatorname{IMG\\_SIZE}^2)$$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compareResults(prediction, image_to_test=4):\n",
    "    \"\"\"\n",
    "    Helper funtion to visualize results\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(ncols=3, dpi=144)\n",
    "    _imgs = imread(imgs[image_to_test])\n",
    "    _imgs = resize(_imgs, (IMG_SIZE, IMG_SIZE))\n",
    "    _mask = imread(masks[image_to_test])\n",
    "    _mask = resize(_mask, (IMG_SIZE, IMG_SIZE))\n",
    "    ax[0].imshow(_imgs, cmap='gray')\n",
    "    ax[1].imshow(prediction.reshape((IMG_SIZE, IMG_SIZE)), cmap='gray')\n",
    "    ax[2].imshow(_mask, cmap='gray')\n",
    "    for ax, label in zip(ax, [\"Original Image\", \"Prediction\", \"Ground Truth\"]):\n",
    "        ax.axis('Off')\n",
    "        ax.set_title(label)\n",
    "    fig.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"NPixels used for training {IMG_SIZE*IMG_SIZE*2}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def features_pixelValue(img, mask):\n",
    "    \"\"\"\n",
    "    Generate features using the pixel value\n",
    "    \"\"\"\n",
    "    img_array = imread(img, as_gray=True)\n",
    "    mask_array = imread(mask, as_gray=True)\n",
    "    # Binarize mask, everything that is bigger than zero is one\n",
    "    # Resize images to reduce computing costs, notice this process makes image values between 0 and 1\n",
    "    img_array = resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    mask_array = resize(mask_array, (IMG_SIZE, IMG_SIZE), preserve_range=True)\n",
    "    mask_array = np.clip(mask_array, 0, 1).round()\n",
    "\n",
    "    np.unique(mask_array, return_counts=True)\n",
    "\n",
    "    # Reshaping so every pixel is a row\n",
    "    features = img_array.reshape(-1, 1)\n",
    "    mask_array = mask_array.reshape(-1, 1)\n",
    "    return features, mask_array"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here I am training the SVM version from scikit-learn, it's up to you to adapt the features matrix to your version. We are training on the first two images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_imgs, all_masks = [], []\n",
    "for img, mask in zip(imgs[:2], masks[:2]):\n",
    "    img_svc, mask_svc = features_pixelValue(img, mask)\n",
    "\n",
    "    # Collecting\n",
    "    all_imgs.append(img_svc)\n",
    "    all_masks.append(mask_svc)\n",
    "\n",
    "# Lets make a matrix\n",
    "imgs_mat = np.vstack(all_imgs)\n",
    "masks_mat = np.vstack(all_masks)\n",
    "\n",
    "svc_pv = SVC(kernel='linear', C=20)\n",
    "svc_pv.fit(imgs_mat, masks_mat)\n",
    "print(\"Done Training\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_to_test = 4\n",
    "im_svc, mask_svc = features_pixelValue(imgs[image_to_test], masks[image_to_test])\n",
    "pred_pv = svc_pv.predict(im_svc)\n",
    "f1 = round(f1_score(mask_svc, pred_pv), 3)\n",
    "print(f\"F1/Dice Score: {f1}\")\n",
    "\n",
    "compareResults(pred_pv, image_to_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see, this is really slow for large images and the black areas inside a cell are not correctly segmented which is normal since we are only using the pixel intensity value. We have zero knowledge of the surroundings.\n",
    "To improve this we can add more features, let's try adding edge information.\n",
    "$$ X = N_{pixels} \\times 2$$\n",
    "$$W = 1 \\times 2$$\n",
    "$$Y = N_{pixels} \\times 1$$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Adding Edge information"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def features_pixelValue_edge(img, mask):\n",
    "    \"\"\"This function will process the image and the image ground truth (AKA mask), the mask will be just resized.\n",
    "        We will generate features for the SVM in order to make predictions,\n",
    "       The first column of the features will be the pixel intensity between 0 to 1\n",
    "       The second column of the features will be the canny filter for edge detection.\n",
    "\n",
    "    \"\"\"\n",
    "    img_array = imread(img, as_gray=True)\n",
    "    mask_array = imread(mask, as_gray=True)\n",
    "\n",
    "\n",
    "    img_array = resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    edges = canny(img_array, sigma=.5)\n",
    "    img_array = img_array.reshape(-1, 1)\n",
    "    edges = edges.reshape(-1, 1)\n",
    "    features = np.hstack([img_array, edges])\n",
    "\n",
    "    mask_array = resize(mask_array, (IMG_SIZE, IMG_SIZE), preserve_range=True)\n",
    "    mask_array = np.clip(mask_array, 0, 1).round()\n",
    "    mask_array = mask_array.reshape(-1)\n",
    "    return features, mask_array"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_imgs, all_masks = [], []\n",
    "N_Train_images_used = 2\n",
    "for img, mask in zip(imgs[:N_Train_images_used], masks[:N_Train_images_used]):\n",
    "    img_svc, mask_svc = features_pixelValue_edge(img, mask)\n",
    "\n",
    "    # Collecting\n",
    "    all_imgs.append(img_svc)\n",
    "    all_masks.append(mask_svc)\n",
    "\n",
    "# Lets make a matrix\n",
    "imgs_mat = np.vstack(all_imgs)\n",
    "masks_mat = np.vstack(all_masks)\n",
    "print(\"Training .....\", end=\"\")\n",
    "svc_pv_edge = SVC(kernel='linear', C=20)\n",
    "svc_pv_edge.fit(imgs_mat, masks_mat.reshape(-1))\n",
    "print(\" Done :)\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_to_test = 5\n",
    "im_svc, mask_svc = features_pixelValue_edge(imgs[image_to_test], masks[image_to_test])\n",
    "pred_pv_edge = svc_pv_edge.predict(im_svc)\n",
    "f1 = np.round(f1_score(mask_svc, pred_pv_edge), 3)\n",
    "print(f\"F1/Dice Score: {f1}\")\n",
    "\n",
    "compareResults(pred_pv_edge, image_to_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Seems it did nothing much, maybe if we improve the image contrast, let's use OTSU's thresholding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Thresholding the image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def features_pixelValue_otsu(img, mask):\n",
    "    \"\"\"\n",
    "    Generate features using the pixel value after using the Otsu's threshold\n",
    "    \"\"\"\n",
    "    img_array = imread(img, as_gray=True)\n",
    "    thr = threshold_otsu(img_array)\n",
    "    img_array = (img_array > thr).astype(float)\n",
    "    mask_array = imread(mask, as_gray=True)\n",
    "    # Binarize mask, everything that is bigger than zero is one\n",
    "    # Resize images to reduce computing costs, notice this process makes image values between 0 and 1\n",
    "    img_array = resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    mask_array = resize(mask_array, (IMG_SIZE, IMG_SIZE), preserve_range=True)\n",
    "    mask_array = np.clip(mask_array, 0, 1).round()\n",
    "\n",
    "    np.unique(mask_array, return_counts=True)\n",
    "\n",
    "    # Reshaping so every pixel is a row\n",
    "    features = img_array.reshape(-1, 1)\n",
    "    mask_array = mask_array.reshape(-1)\n",
    "    return features, mask_array"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_imgs, all_masks = [], []\n",
    "N_Train_images_used = 2\n",
    "for img, mask in zip(imgs[:N_Train_images_used], masks[:N_Train_images_used]):\n",
    "    img_svc, mask_svc = features_pixelValue_otsu(img, mask)\n",
    "\n",
    "    # Collecting\n",
    "    all_imgs.append(img_svc)\n",
    "    all_masks.append(mask_svc)\n",
    "\n",
    "# Lets make a matrix\n",
    "imgs_mat = np.vstack(all_imgs)\n",
    "masks_mat = np.vstack(all_masks)\n",
    "print(\"Training .....\", end=\"\")\n",
    "svc_otsu_pv = SVC(kernel='linear', C=20)\n",
    "svc_otsu_pv.fit(imgs_mat, masks_mat.reshape(-1))\n",
    "print(\"Done :)\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_to_test = 5\n",
    "im_svc, mask_svc = features_pixelValue_otsu(imgs[image_to_test], masks[image_to_test])\n",
    "pred_otsu_pv = svc_otsu_pv.predict(im_svc)\n",
    "f1 = round(f1_score(mask_svc, pred_otsu_pv), 3)\n",
    "print(f\"F1/Dice Score: {f1}\")\n",
    "\n",
    "compareResults(pred_otsu_pv, image_to_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Take into the account that the training is done using a smaller image and just two of the for training. Also the results are compared with just one image, that probably not enough to draw a proper conclusion. Let's use something more powerful."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Adding more features using more information"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def features_multiscale(img, mask):\n",
    "    img_array = imread(img, as_gray=True)\n",
    "    mask_array = imread(mask, as_gray=True)\n",
    "    # Binarize mask, everything that is bigger than zero is one\n",
    "    # Resize images to reduce computing costs, notice this process makes image values between 0 and 1\n",
    "    img_array = resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    mask_array = resize(mask_array, (IMG_SIZE, IMG_SIZE), preserve_range=True)\n",
    "    mask_array = np.clip(mask_array, 0, 1).round()\n",
    "\n",
    "    features = multiscale_basic_features(img_array,\n",
    "                                         intensity=True,\n",
    "                                         edges=True,\n",
    "                                         texture=True,\n",
    "                                         sigma_min=1,\n",
    "                                         sigma_max=16)\n",
    "    mask_array = mask_array.reshape(-1, 1)\n",
    "    features = features.reshape(-1, features.shape[-1])\n",
    "    return features, mask_array"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_imgs, all_masks = [], []\n",
    "N_Train_images_used = 2\n",
    "for img, mask in zip(imgs[:N_Train_images_used], masks[:N_Train_images_used]):\n",
    "    img_svc, mask_svc = features_multiscale(img, mask)\n",
    "\n",
    "    # Collecting\n",
    "    all_imgs.append(img_svc)\n",
    "    all_masks.append(mask_svc)\n",
    "\n",
    "# Lets make a matrix\n",
    "imgs_mat = np.vstack(all_imgs)\n",
    "masks_mat = np.vstack(all_masks)\n",
    "print(\"Training .....\", end=\"\")\n",
    "svc_multiscale = SVC(kernel='linear', C=20)\n",
    "svc_multiscale.fit(imgs_mat, masks_mat.reshape(-1))\n",
    "print(\"Done :)\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For the sake of clarity the feature matrix looks like, remember, this matrix is generated from the image of the cells."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(imgs_mat)\n",
    "df.index.name = \"PixelNum\"\n",
    "df.columns = [f\"feature_{i}\" for i in range(df.shape[1])]\n",
    "df.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_to_test = 5\n",
    "im_svc, mask_svc = features_multiscale(imgs[image_to_test], masks[image_to_test])\n",
    "pred_multiscale = svc_multiscale.predict(im_svc)\n",
    "f1 = round(f1_score(mask_svc, pred_multiscale), 3)\n",
    "print(f\"F1/Dice Score: {f1}\")\n",
    "\n",
    "compareResults(pred_multiscale, image_to_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You should also play with increasing the contrast, sharpening the image.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}