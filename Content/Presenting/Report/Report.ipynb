{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Report of Project 05: 'Implementation and evaluation of machine learning (support vector machine) segmentation\n",
    "## Data analysis project for bachelor in molecular biotechnology at Heidelberg University\n",
    "### 19.07.21\n",
    "### Authors: Michelle Emmert, Juan Hamdan, Laura Sanchis and Gloria Timm\n",
    "\n",
    "*ich werde kommentare, anmerkungen, noch zu klärende fragen... immer in kursiv schreiben*\n",
    "\n",
    "*Idee: unseren algorithmus anhand eines bildes erklären und dieses immer wieder im report zeigen um die veränderungen\n",
    "zu zeigen & am ende dice berechnen --> veranschaulichen*\n",
    "\n",
    "*Unterüberschriften noch einfügen*\n",
    "\n",
    "# Abstract\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Table of contents *ggf. noch 2.1, 2.2 etc.*\n",
    "**1. Introduction** <br>\n",
    "**2. Our Datasets** <br>\n",
    "**3.** <br>\n",
    "**4. Pre-processing** <br>\n",
    "**5. Implementation of support vector machine** <br>\n",
    "**6. Evaluation using the Dice coefficient** <br>\n",
    "**7. Results** <br>\n",
    "**8. Discussion** <br>\n",
    "**9. Bibliography**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 6. Dice coefficient\n",
    "## 6.1 The theory behind the dice coefficient\n",
    "The Dice coefficient is a score to evaluate and compare the accuracy of a segmentation (method).\n",
    "Needed for its calculation are the segmented image as well as a corresponding binary reference point also called\n",
    "ground truth.\n",
    "As ground truth image researchers mostly use the segmentation result of humans. We will use the ground truth images\n",
    "provided with our data sets, which we suspect to be acquired by this method.\n",
    "Using the ground truth image, it is possible to assign the labels true positive (TP), false positive (FP) and false\n",
    "negative (FN) to each pixel of the segmented image.\n",
    "This information is then used to calculate the dice coefficient using formula (1):\n",
    "\n",
    "(1) dice = ${\\frac{2TP}{2TP + FP + FN}}$\n",
    "\n",
    "\n",
    "The dice is element of [0,1]. 0 indicates that the ground truth and the segmentation result do not overlap. 1 on the\n",
    "other hand shows a 100% overlap of ground truth and segmented image.\n",
    "\n",
    "## 6.2 Implementing the dice coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "```\n",
    "import Dicescore.py ???\n",
    "\n",
    "```\n",
    "\n",
    "```python\n",
    "###import images (prediction & ground truth) as arrays\n",
    "\n",
    "###compute dice score\n",
    "def dice_coefficient(imgt, imgp):  # t = ground truth, p = SVM prediction\n",
    "    assert imgt.dtype == np.bool #the images with type array are converted to type bool\n",
    "    assert imgp.dtype == np.bool #the images with type array are converted to type bool\n",
    "    intersection = np.logical_and(imgt, imgp) #compute the truth value of x1 AND x2 element-wise = sums all pixels where both gt and pred have the value 'true'\n",
    "    union = imgt.sum() + imgp.sum() #compute the truth value of x1 OR x2 element-wise = sums all pixels where either gt or pred (or both) have the value 'true'\n",
    "    if intersection + union == 0:\n",
    "        return ('dice cannot be calculated - no intersection') #because it is mathematically not allowed to divide by 0, which would happen if gt and pred don't intersect\n",
    "    else:\n",
    "        dice = (2 * intersection) / (union + intersection) #using the dice formula to calculate the dice IF gt and pred intersect\n",
    "        return dice #print out dice\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6.3 Synthetic images\n",
    "### 6.3.1 How does it work, and what is our goal?\n",
    "The concept behind creating synthetic images is to use algorithms and images which are already available to generate\n",
    "new ones. Although our first objective was to just use these new images to test our code for the dice score, we realized\n",
    "while researching for this topic that synthetic images have an immense potential, most of all for the training of machine\n",
    "learning algorithms. The bigger the training dataset is, the better the performance of the program. Our data set consists\n",
    "of 28 images of cell nuclei, and because we have to slit it up between the training and the test data set, we won't be\n",
    "able to use all images to train our SVM. Because of this, we decided to implement our synthetically produced images not\n",
    "only for the testing of the dice score, but to enlarge our training data pool for our Support Vector Machine, and check\n",
    "afterwards if its efficiency is better with our dice score. There are many methods that can be used in order to generate\n",
    "synthetic images. Because of the scope of our project and the kind of images that we want to produce, we focused on image\n",
    "composition and domain transfer.\n",
    "\n",
    "### 6.3.2 Image composition\n",
    "Image composition consists of taking various foreground images, which have been segmented out of their backgrounds or\n",
    "have a .png format to begin with, and paste them onto different backgrounds. The foreground images can be modified by\n",
    "using different light conditions, contrasts, zooms or rotations in order to achieve more variety in the results.\n",
    "--> probably not as useful for our case as cells are usually in front of dark background, but still an option to evaluate\n",
    "--> will the Dice Score get better with that method?\n",
    "\n",
    "*Here we could insert the code from my Jupyter notebook -> issue: it hasn't been written by us\n",
    "(and it hasn't been modified either...), so maybe it would be better to just use our own code when we write it.*\n",
    "\n",
    "### 6.3.3 Domain randomization\n",
    "The idea here is that there is a model from the object class you want to train your model for, and in that model,\n",
    "every parameter from the object and its environment that is not necessary for its recognition by the machine has been\n",
    "randomized. This means for example size, lighting or color, and there are very powerful tools to do this, like Unity or\n",
    "Blender. <br>\n",
    "*--> probably more useful, as we have changes in size, dividing or leaving cells etc. However, it is usually\n",
    "used to train robots to work from a simulation to reality, so it might be a bit too much.*\n",
    "\n",
    "# Support Vector Machine\n",
    "\n",
    "1. Tensorflow --> an Option?\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}