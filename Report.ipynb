{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Report of Project 05: Implementation and Evaluation of Machine Learning (Support Vector Machine) Segmentation\n",
    "## Data analysis project - B.Sc. Molecular Biotechnology Heidelberg University\n",
    "### 19 Juli 2021\n",
    "### Authors: Michelle Emmert, Juan Andre Hamdan, Laura Sanchis Pla and Gloria Timm\n",
    "\n",
    "# Abstract\n",
    "Support Vector Machines, also known as SVMs, are supervised learning models with associated learning algorithms that\n",
    "analyze data for classification and regression analysis. One of their many uses is in nuclei segmentation for cell counting and cancer grading.\n",
    "This report describes an algorithm designed around an SVM, which was developed using three sets of microscopic images.\n",
    "Pursuing the overall goal to implement and evaluate an SVM for cell nuclei segmentation, the algorithm contains two pre-processing\n",
    "methods: Gaussian filtering and Watershed. To prepare the data for the SVM, two methods for data reduction were applied:\n",
    "Principal Component Analysis (PCA) and Tiles. *hier noch kurz erklären??*\n",
    "*SVM*\n",
    "To evaluate the algorithms' performance the Dice Score was used.\n",
    "We find that *XXX*.\n",
    "\n",
    "\n",
    "*TO BE DONE*\n",
    "\n",
    "Their theoretical foundations and their experimental success encourage further research on their characteristics, as well\n",
    "as their further use.\n",
    "\n",
    "\n",
    "\n",
    "# Table of contents\n",
    "**1. Introduction** <br>\n",
    "**2. The Dataset** <br>\n",
    "**3. The algorithm's pipeline** <br>\n",
    "**4. Pre-processing** <br>\n",
    "**4.1 Gaussian filter** <br>\n",
    "**4.2 Watershed** <br>\n",
    "**4.3 Principle Component Analysis** <br>\n",
    "**5. Data reduction** <br>\n",
    "**5.2 Tiles** <br>\n",
    "**6. Synthetic Images** <br>\n",
    "**6.1 Definition and Goal** <br>\n",
    "**6.2 Image composition** <br>\n",
    "**6.3 Domain randomization** <br>\n",
    "**7. Support Vector Machine** <br>\n",
    "**7.1 The Mathematical Background** <br>\n",
    "**7.2 The loss function** <br>\n",
    "**7.3 Stochastic gradient decent to minimize the loss gradient** <br>\n",
    "**7.4 K-Fold Cross validation** <br>\n",
    "**8. Evaluation using the Dice coefficient** <br>\n",
    "**8.1 The Theory behind the Dice Coefficient** <br>\n",
    "**8.2 Unittesting the Dice Coefficient** <br>\n",
    "**9. Results** <br>\n",
    "**10. Discussion** <br>\n",
    "**11. Bibliography**\n",
    "\n",
    "# List of abbreviations\n",
    "| Abbreviation | Full name |\n",
    "| --- | --- |\n",
    "| CD | cluster of differentiation |\n",
    "| CV | K-Fold Cross validation |\n",
    "| FN | false negative |\n",
    "| FP | false positive |\n",
    "| GFP | Green fluorescent protein |\n",
    "| LOOCV | eave one out cross-validation |\n",
    "| ML | machine learning |\n",
    "| PCA  | Principle Component Analysis |\n",
    "| PC | Principle Component |\n",
    "| SGD | Stochastic Gradient Descent |\n",
    "| SVM | Support Vector Machine |\n",
    "| TP | True positive |\n",
    "\n",
    "\n",
    "# 1. Introduction\n",
    "Image segmentation is a process, during which important features of a picture are extracted, to aid analysis and retrieval\n",
    "of information. This is done by assigning labels to all pixels of the image. Pixels sharing defined traits, are assigned the same label. (Khan and Ravi, 2013)\n",
    "Nuclei segmentation is a subform of image segmentation. Its goal is to automatically separate nuclei from their background.\n",
    "This allows machine counting of nuclei and cells (Schüffler et al., 2013).\n",
    "\n",
    "During laboratory work, manual cell counting of microscopic images is a cumbersome and error-prone process. However, since\n",
    "the number of cells contains important information, counting remains indispensable.\n",
    "Automatic cell counting via nuclei segmentation is therefore used to accelerate and improve the overall procedure. (Schüffler et al., 2013)\n",
    "\n",
    "In addition to its use in biological laboratories, nuclei segmentation also advances cancer grading in medical practice.\n",
    "Cancer grading describes the process of classifying and grading a cancer based on cancer histopathology. It is\n",
    "an essential step in quantifying the degree of malignancy and thus key to predict patient prognosis and prescribe a treatment.\n",
    "Currently, cancer grading is still often done manually via visual analysis of tissue samples.\n",
    "This method is somewhat problematic given its inter- and intra-observer variability regarding the gradings quality, its low reproducibility\n",
    "as well as the disproportionate time needed for completion. (Veta et al., 2013; Schüffler et al., 2013)\n",
    "\n",
    "Using an SVM, is an auspicious way to accomplish nuclei segmentation (Schüffler et al., 2013).\n",
    "We use the SVM to differentiate between foreground and background pixels. Foreground pixels are subsequently labeled as\n",
    "nuclei and displayed white. Background pixels are colored black.\n",
    "\n",
    "The images require pre-processing to enhance the picture quality, a crucial prerequisite for an effective image segmentation\n",
    "via SVM. To evaluate the segmentation quality, the Dice Coefficient is used.\n",
    "\n",
    "# 2. The Dataset\n",
    "The data consist of three datasets with a total of 28 images, all showing nuclei.\n",
    "The pictures of the first dataset show GFP-transfected GOWT1 mouse embryonic stem cells. The second set of images display\n",
    "Histone-2B-GFP expressing HeLa cells, while our third set consists of pictures of mouse embryonic fibroblasts, in which\n",
    "CD-antigens were tagged with enhanced-GFP.\n",
    "All images are microscopic images of nuclei, however the three sets vary greatly in other features with additional challenges for our image analysis.\n",
    "•\tdifferent formats (1024 x 1024, 1100 x 700, 1344 x 1024),\n",
    "•\tacquired  differently\n",
    "•\tdifferent numbers of nuclei, within a range of 15-65 nuclei per image.\n",
    "•\tdifferent brightness and resolution\n",
    "•\twhite flashes, clustering of nuclei or nuclei leaving the image or undergoing mitosis.\n",
    "\n",
    "# 3. The algorithm pipeline\n",
    "\n",
    "*INSERT IMAGES OF ALGORITHM*\n",
    "\n",
    "\n",
    "# 4. Pre-processing\n",
    "We implemented two different pre-processing methods in our SVM algorithm in order to improve the raw\n",
    "images quality and consequently achieve better segmentation results.\n",
    "\n",
    "## 4.1 Gaussian filter\n",
    "As our first pre-processing method, we used a Gaussian filter. This technique was shown to be particularly useful for the filtering of noisy pictures.\n",
    "This is the case, since the results of the filtering show a relative independence on the variance value of the Gaussian\n",
    "kernel (Gedraite, E. et al. 2011). It might turn out to be problematic that the use of Gaussian filters can give\n",
    "rise to edge position displacement, edges vanishing, and phantom edges (Deng, G. et al. 1993)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.2) /private/var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T/pip-req-build-iwig8vc6/opencv/modules/imgproc/src/smooth.dispatch.cpp:617: error: (-215:Assertion failed) !_src.empty() in function 'GaussianBlur'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31merror\u001B[0m                                     Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-5-9bf3b1c88346>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mcv2\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0moriginal\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcv2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'../Data/N2DH-GOWT1/img/t52.tif'\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# apply the gauss filter\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m \u001B[0mfiltered\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcv2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mGaussianBlur\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moriginal\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;36m5\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimshow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfiltered\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtitle\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Gauss Filtered'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31merror\u001B[0m: OpenCV(4.5.2) /private/var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T/pip-req-build-iwig8vc6/opencv/modules/imgproc/src/smooth.dispatch.cpp:617: error: (-215:Assertion failed) !_src.empty() in function 'GaussianBlur'\n"
     ]
    }
   ],
   "source": [
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "original = cv2.imread('../Data/N2DH-GOWT1/img/t52.tif')  # apply the gauss filter\n",
    "filtered = cv2.GaussianBlur(original, (5, 5), 0)\n",
    "plt.imshow(filtered)\n",
    "plt.title('Gauss Filtered')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.2 Watershed\n",
    "As our second pre-processing method, we used Watershed, a gradient-ascend-based super pixel algorithm that has its origins in mathematical morphology.\n",
    "In watershed segmentation an image is regarded as a topographic landscape with ridges and valleys. The elevation values of the\n",
    "landscape are typically defined by the gray values of the respective pixels or their gradient magnitude.\n",
    "\n",
    "To make Watershed easier to understand, one can think of an image as a surface. The bright pixels represent mountain tops, while the dark\n",
    "pixels symbolize valleys. The surface is punctured in some valleys and then slowly submerged into a water bath. As the water\n",
    "pours into each puncture, it starts to fill the valleys. However, the water from different punctures should not mix.\n",
    "Therefore, dams need to be built where different waters first touch.\n",
    "These dams at the boundaries of the water basins are equivalent to the boundaries of image objects.\n",
    "The output image of a watershed algorithm thus is the original image, in which every object is encircled."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from SVM_Segmentation.preprocessing.watershed import watershed\n",
    "if __name__ == '__main__':\n",
    "    ws = watershed(\"/Users/juanandre/PycharmProjects/2021-topic-04-team-05/Data/N2DH-GOWT1/img/t52.tif\")\n",
    "    plt.imshow(ws)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.3 Principal Component Analysis\n",
    "Principal component analysis simplifies the complexity of high-dimensional data by geometrically projecting them onto lower dimensions\n",
    "called principal components (PCs) while preserving as much of the data's variation as possible (Lever, 2017).\n",
    "These principal components are eigenvectors of the data's covariance matrix and often computed by\n",
    "eigendecomposition of the data covariance matrix. (Hedge, A. 2006)\n",
    "\n",
    "PCA essentially rotates the set of points around their mean in order to align them with the principal components.\n",
    "This moves as much of the variance as possible into the first few dimensions. The values in the remaining dimensions,\n",
    "therefore, tend to be small and may be dropped with minimal loss of information. (Jolliffe, I. 2016)\n",
    "\n",
    "We perform the PCA as part of our pre-processing. By retaining a selected number of PCs that together explain 95% of the variance of the\n",
    "image, we aim to reduce noise and increase contrast of the original image.\n",
    "Therewith we hope to improve the quality of the SVMs segmentation.\n",
    "\n",
    "After selecting the PCs, the image is uptransformed to its initial size.\n",
    "\n",
    "Because SVM is an algorithm that requires its features to be normalized, the PCA is performed with StandardScaler applied.\n",
    "This function scales the features to have zero as the mean and a standard deviaton of 1, to give\n",
    "it the feel and the properties of a standard normal distribution. As a positive side effect this also refines the SVMs prediction accuracy."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from SVM_Segmentation.preprocessing.pca import convert_pca\n",
    "if __name__ == '__main__':\n",
    "    image_read1 = io.imread('/Users/juanandre/PycharmProjects/2021-topic-04-team-05/Data/N2DH-GOWT1/img/t52.tif')\n",
    "    pca1 = convert_pca(image_read1, 0.9)\n",
    "    plt.imshow(pca1)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Data Reduction\n",
    "As the images in our dataset consist of more than one million pixels each, running the SVM would take a lot of computational power and runtime.\n",
    "To decrease both, data reduction should be performed beforehand.\n",
    "The two possibilities we thought of, are resize form skimage and cutting the image into tiles before averaging over each tile.\n",
    "\n",
    "Resize from skimage cuts the image into a pre-defined scaling factor. We cut all images to 250 x 250.\n",
    "\n",
    "## 5.1 Tiles\n",
    "While PCA reduces data specifically, tiles-rendering is a simple approach that reduces data unspecifically by\n",
    "exploiting the fundamental properties of a problem space.\n",
    "The concept behind tiles is to save computational power, by splitting the image into multiple sets of N x N tiles\n",
    "and then calculate the average of each tile. The average intensity value of a specific tile is assigned to all pixels, belonging to\n",
    "this tile. Lastly, all tiles are reassembled to form the resulting image. (Rastar, A. 2019)\n",
    "\n",
    "As our tiles algorithm reduced the images quality in large measure, we decided to not use it as part of our algorithm."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from SVM_Segmentation.preprocessing.tiles import tiles\n",
    "from SVM_Segmentation.pixel_conversion import one_d_array_to_two_d_array\n",
    "from skimage import io\n",
    "image = io.imread('/Users/juanandre/PycharmProjects/2021-topic-04-team-05/Data/N2DH-GOWT1/img/t52.tif')\n",
    "tiled = tiles(image, 50)\n",
    "tiled = one_d_array_to_two_d_array(tiled)\n",
    "plt.imshow(tiled)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6. Synthetic Images\n",
    "## 6.1 Definition and Goal\n",
    "The basic idea behind creating synthetic images is to use algorithms and already available images to generate\n",
    "new images (Dunn et al., 2019). Our first objective was to simply use these new images to test our code for the dice score.\n",
    "But while researching on this topic, we realized that synthetic images have an immense potential, especially for the training\n",
    "phase of a machine learning algorithm.\n",
    "This is particularly useful as our data encompasses only 28 images, which leads to a training data set of 27 images at max.\n",
    "By expanding our training set with diverse images of good quality, we expect a more accurate model (Mayer et al., 2017).\n",
    "There are various methods for the generation of synthetic images (Ward et al., 2019). Because of the scope of our project and the\n",
    "kind of images we wanted to produce, we focused on image composition and domain randomization.\n",
    "\n",
    "## 6.2 Image composition\n",
    "To produce synthetic masks, a white circle is drawn on top of a black background.\n",
    "While the background stays the same across all images, the circle size and position gets modified.\n",
    "Our algorithm iterates through the random position and scaling generator. This produces random, black-and-white only images.\n",
    "These masks are used to test our Dice Score.\n",
    "\n",
    "## 6.3 Domain randomization\n",
    "In order to create synthetic microscopic cell images, we used a method called domain randomization.\n",
    "It requires collecting various foreground images, either by separating the images from their\n",
    "backgrounds or by using images in .png format. These foreground images are then pasted onto different backgrounds. (Tripathi, 2019)\n",
    "To obtain more variety among the resulting synthetic images, the foreground images can be modified using different contrasts,\n",
    "zooms or rotations (Ward et al., 2019; Alghonaim and Johns, 2020).\n",
    "\n",
    "For this project, we used domain randomization to generate a new set of images with cells cut from our 28 images data set.\n",
    "After rotating and scaling the cells, they were pasted at random positions onto a background, which had also been cut and\n",
    "scaled from the dataset.\n",
    "These new images were used further on to enlarge and enrich our training data set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "original = cv2.imread('/Users/juanandre/PycharmProjects/2021-topic-04-team-05/Data/synthetic_cell_images/N2DH-GOWT1_t01/generated_images_img/3.tif')  # apply the gauss filter\n",
    "plt.imshow(original)\n",
    "plt.title('Synthetic Generated Image')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 7. Support Vector Machine\n",
    "In 1992, Vapnik and coworkers proposed a supervised algorithm, developed from statistical learning, to solve classification\n",
    "problems (Vapnik et al., 1992). Since then, their machine learning method evolved into what is now known as\n",
    "SVM: a class of algorithms for classification, regression and other applications that\n",
    "represents the current state of the art in the field (Suthaharan, 2016; Guanasekaran, 2010; Christianini and Ricci, 2008).\n",
    "\n",
    "By providing a training data set with binary labels, the SVM is able to learn how to classify data points using certain\n",
    "features. This capability can subsequently be used to classify new data, called test data, using its features (Thai et al., 2012).\n",
    "SVMs have been successfully applied to several applications, ranging from time series prediction and face recognition\n",
    "to biological data processing for medical diagnosis (Evgeniou, 2001).\n",
    "In image processing, SVMs are used for one of the classical challenges: image classification (Evgeniou, 2001).\n",
    "\n",
    "## 7.1 The Mathematical Background\n",
    "The mathematical concepts are key to understand how SVMs work.\n",
    "The goal of an SVM is, to separate data points into two groups of provided labels with an optimal hyperplane.\n",
    "This hyperplane is described by"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\\begin{equation}\n",
    "(2) \\ w * x + b = 0\n",
    "\\end{equation}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "and fulfilling the following condition"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\\begin{equation}\n",
    "(3) \\ h =\n",
    "\\left\\{\n",
    "  \\begin{aligned}\n",
    "    +1 \\ \\ if \\ \\ w⋅x_i +b≥ +1 - \\varepsilon_i\\\\\n",
    "    -1 \\ \\ if \\ \\ w⋅x_i +b< -1 - \\varepsilon_i\n",
    "  \\end{aligned}\n",
    "  \\right.\n",
    "  \\ \\ \\varepsilon \\geqq 0 \\ \\forall_i \\ ; \\ i=1...m\n",
    "\\end{equation}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "whilst for two dimensions $w = (a, -1)$, whereas $a$ is the slope of the line, and $x = (x_1, x_2)$ and represents a\n",
    "data point. $\\varepsilon$ is a variable, standing for the inaccuracy of the hyperplane. It is added to the constraint to\n",
    "prevent overfitting of the model onto the training set. Without $\\varepsilon$ the geometric margin M is called a hard margin,\n",
    "as it does not allow data points of one group to be incorrectly labeled as members of the other group. This does not result in\n",
    "the best model, as single incorrectly assigned data points, can have a lower impact on the quality of the model, than a suboptimal\n",
    "hyperplane. Therefore, $\\varepsilon$ is introduced and thereupon M is called a soft margin.\n",
    "\n",
    "To choose the optimal hyperplane we need to minimize the margin as follows."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\\begin{equation}\n",
    "(4)\\ M = min_{i=1...m} \\ y_i(\\frac{w}{||w||}*x + \\frac{b}{||w||})\n",
    "\\end{equation}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The largest margin M out of all margins computed in our training phase, will be selected. The variables w and b are\n",
    "divided by the length of the vector w calculated with the Euclidean norm formula, as they need to be scale invariant.\n",
    "The aim is, to find the values for w and b, corresponding to the largest margin.\n",
    "\n",
    "This leads us to the following optimization problem.\n",
    "We want to maximize M:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\\begin{equation}\n",
    "(5) \\ max_{w,b,\\varepsilon} M\n",
    "\\end{equation}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This maximization problem is equivalent to"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\\begin{equation}\n",
    "(6) \\ max_{w,b,\\varepsilon} \\frac{1}{||w||} \\ + \\ \\sum^{m}_{i=1}\\varepsilon_i\n",
    "\\end{equation}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "and can be rewritten as the following minimalization problem."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\\begin{equation}\n",
    "(7) \\ min_{w,b,\\varepsilon}  \\ \\frac{1}{2}||w||^2\\ + \\ C\\sum^{m}_{i=1}\\varepsilon_i \\\\\n",
    "subject \\ to \\ \\  y_i(w⋅x_i+b)≥1− \\varepsilon_i \\ , \\varepsilon \\geqq 0 \\ \\forall_i \\ , \\ i=1...m\n",
    "\\end{equation}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The regularization parameter C is chosen by the user and determines the weight of $\\varepsilon$.\n",
    "A larger C leads to a higher penalty for errors and therefore to a harder margin.\n",
    "\n",
    "In order to solve this constrained optimization problem, in which we want to maximize the margin while fulfilling our\n",
    "conditions or constraints, Lagrange multipliers are used. The idea behind this mathematical concept is that at the optimum,\n",
    "the gradient of our objective function is parallel or antiparallel to the gradient of the constraint function.\n",
    "Therefore, both have to be equal or a multiple of each other, which is what the Lagrange multiplier is showcasing."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\\begin{equation}\n",
    "(8) \\ \\nabla f(x) - \\alpha \\nabla g(x) = 0\n",
    "\\end{equation}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "When we insert our functions, we get the following Lagrangian function:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\\begin{equation}\n",
    "(9) \\ f(x)= \\frac{1}{2}||w||^2\\ + \\ C\\sum^{m}_{i=1}\\varepsilon_i\n",
    "\\\\(10) \\ g(x) = y_i(w⋅x_i+b) - 1 + \\varepsilon_i\n",
    "\\\\(11) \\ \\mathcal{L}(w,b,\\alpha) =\\frac{1}{2}||w||^2\\ + \\ C\\sum^{m}_{i=1}\\varepsilon_i - \\sum^{m}_{i=1}\\alpha_i[y_i\n",
    "(w⋅x_i+b) - 1 + \\varepsilon_i]\n",
    "\\end{equation}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to solve this Lagrange problem, it is relaxed into a dual problem: The constraints are incorporated\n",
    "into the function, resulting in it only depending on the Lagrange multipliers. This facilitates the solving.\n",
    "Below, the two constraints for the dual problem are described:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\\begin{equation}\n",
    "(12) \\ \\nabla_w \\mathcal{L}(w,b,\\alpha) = w - \\sum^{m}_{i=1} \\alpha_i y_i x_i = 0\n",
    "\\\\ (13) \\ \\nabla_b \\mathcal{L}(w,b,\\alpha) = - \\sum^{m}_{i=1} \\alpha_i y_i = 0\n",
    "\\end{equation}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If they are inserted into the Lagrange function, the result of the dual problem is the following:\n",
    "\\begin{equation}\n",
    "(14) \\ max_{\\alpha}  \\ \\sum^{m}_{i=1}\\alpha_i - \\frac{1}{2}\\sum^{m}_{i=1}\\sum^{m}_{j=1}\\alpha_i\\alpha_j y_i y_j x_i · x_j \\\\\n",
    "subject \\ to \\ \\ 0≤\\alpha_i≤C, i=1...m, \\sum^{m}_{i=1}\\alpha_iy_i = 0\n",
    "\\end{equation}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the above equation, it becomes clear that the maximization depends solely on the dot product of the support vectors\n",
    "$x_i · x_j$. This is an advantage when dealing with data that is not linearly separable. The 'trick' is to transform the data\n",
    "into a higher dimension, in which a separating hyperplane can be found. However, for a large dataset, calculating the transformation\n",
    "would be a very time-consuming operation. For that reason, instead of actually calculating the transformation, the Kernel trick is used.\n",
    "This means a function is used, which calculates the dot product of $x_i · x_j$ as if the two were in a higher dimension.\n",
    "\n",
    "(Burges, 1998)\n",
    "\n",
    "Whenever this transformation is needed because data that is not linearly separable, non-linear kernels like the Gaussian radial basis function (RBF) are used.\n",
    "For linearly separable data, mapping the data points into a higher dimensional space is not needed and therefore a linear kernel is sufficient. (Hsu, 2016)\n",
    "The linear kernel function can be described as follows:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\\begin{equation}\n",
    "(15) \\ K(x_i, x_j)=\\phi(x_i) · phi(x_j)\n",
    "\\end{equation}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "So it only describes the vector product. Other kernel functions implement other parameters into this function so that,\n",
    "it can calculate the vector product in higher dimensions.\n",
    "\n",
    "Non-linear kernels allow for better predictive performance than the linear kernel, because the linear kernel is a degenerate version\n",
    "of the RBF kernel and thus its predictive performance cannot pass that of the RBF kernel (Keerthi, 2003).\n",
    "\n",
    "However, linear kernels have some advantages over non-linear kernels.\n",
    "Training an SVM with a linear kernel is much faster than with a non-linear kernel.\n",
    "Additionally, when working with a dataset that has many features and a smaller amount of training examples, there is no significant difference\n",
    "in the performance of linear kernels compared to non-linear kernels.\n",
    "In this case, non-linear mapping does not improve the performance. (Hsu, 2016)\n",
    "\n",
    "## 7.2 Theory to Practice: The loss function\n",
    "The loss quantifies the error for misclassified samples, when the classification predicted by the SVM, and the actual classification are unequal.\n",
    "For samples where both are the same, the loss is 0.\n",
    "The loss thus serves as a measure for how bad our model is doing in classifying the training sets samples. (Jakkula, 2006; Evgeniou et. al, 2000)\n",
    "\n",
    "Equation (7) describes the so-called loss function. It contains w squared to penalize higher weights, and it also\n",
    "depends on the hinge loss, which is a value for the misclassified samples, and their importance, depending on our\n",
    "regularization parameter or soft margin factor, C. The bigger C, the harder our margin, because misclassified\n",
    "samples will have a big impact on the cost function and make it bigger. (Burges, 1998)\n",
    "C is defined to balance out both margin maximization and loss. (Friedrichs and Igel, 2005)\n",
    "\n",
    "As described above, the loss function (7) should be minimized to maximize the margin.\n",
    "It is the objective function of our machine learning algorithm.\n",
    "The important part of the loss function, the part that helps to maximize the margin, is the hinge loss, the second part of equation (7). (Jakkula, 2006)\n",
    "\n",
    "To explain it more clearly, (7) could also be written as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "(17) \\ hingeloss = C\\sum^{m}_{i=1}\\varepsilon_i\\ = C \\ [ \\frac{1}{N}\\sum^{m}_{i=1} max(0,1-y_i ⋅ (w ⋅ x_i + b))] \\\\\n",
    "(18) \\ loss =  \\ \\frac{1}{2}||w||^2\\ + \\ hingeloss\n",
    "\\end{equation}\n",
    "\n",
    "## 7.3 Theory to Practice: Stochastic gradient decent to minimize the loss gradient\n",
    "In order to minimize the loss function, its gradient is calculated.\n",
    "A common method to minimize this function is called Gradient Descent.\n",
    "The gradient $∇P(θ)$ of an objective function $P(θ)$, which is parameterized by the model's parameters $θ$, is calculated.\n",
    "$∇P(θ)$ represents the slope with the highest inclination of our function.\n",
    "During Gradient Decent, the parameters are updated in the opposite direction of the gradient. This process is repeated until a\n",
    "(local) minimum is reached, by taking steps determined beforehand by the learning rate.\n",
    "Or, to put it differently, the direction of the slope of the surface described by $P(θ)$ is followed downwards to its lowest\n",
    "point. (Ruder, 2017)\n",
    "Different kinds of gradient descents mostly only differ in the amount of data they use to compute the gradient. Essentially,\n",
    "there is a trade-off between accuracy of the parameter update, and the runtime.\n",
    "As part of our SVM, we used Stochastic Gradient Descent (SGD). In contrast to the basic gradient descent, SGD does not use\n",
    "all the data for its calculation, but only a randomly selected part of it, called stochastic representation (Johnson and Zhang, 2013).\n",
    "This reduces computation time significantly and makes the program faster (Johnson and Zhang, 2013).\n",
    "\n",
    "## 7.4 K-Fold Cross validation\n",
    "Validation is a widely used technique in data science to evaluate how stable a machine learning (ML) model is and to\n",
    "assess how well the model would generalize to new, independent data. Relevant for these two characteristics is the ML's\n",
    "ability to differentiate between relevant patterns and noise in the data available (Vabalas et. al, 2019). As a measure\n",
    "for how good the ML is able to achieve this, the bias-variance trade-off can be used (Geman et. al, 1992; Berrar, 2019).\n",
    "Bias and variance are both sources of error in ML generalization. With increasing model complexity, bias decreases and\n",
    "variance increases monotonically (Yang et. al, 2020). In short:\n",
    "High bias indicates an 'underfitting' model, which is neither able to classify its training data nor new data well,\n",
    "because it captures too little patterns.\n",
    "High variance indicates an 'overfitting' model that is overly sensitive to inherent noise and random pattern in it's\n",
    "training data and for that reason performs poorly on new data. (Yang et. al, 2020)\n",
    "Optimally both bias and variance could be minimized (Geman et. al, 1992; Berrar, 2019).\n",
    "However, in reality just the right balance is needed to create an optimal model (Yang et. al, 2020).\n",
    "\n",
    "One validation technique is k-fold cross validation (CV).\n",
    "In CV, the data available is split into $k$ subsets. The data encompasses $n$ dissimilar samples. $k$ is a random\n",
    "integer between 1 and $n$. For each iteration, $k-1$ subsets are used as training data, while the remaining subsets are\n",
    "used to test the model and are thus part of the validation set.\n",
    "To put it differently: each data sample is part of the testing data once and part of the training data for all other\n",
    "iterations. (Vabalas et. al, 2019)\n",
    "*This approach substantially reduces bias, as it uses most data points for fitting. Simultaneously variance also decreases.\n",
    "But as only one datapoint is used for testing in each iteration, higher variation in testing model effectiveness\n",
    "can occur (Berrar, 2019).*\n",
    "\n",
    "For the implementation, we used Stratified K-Fold, which creates different splits from the train set. The test set is\n",
    "separated from the training process and does not undergo splitting by cross validation, so that the segmentation\n",
    "results are not biased.\n",
    "Then, for the different splits of the train sets, the weight vector is calculated. In order to obtain a single\n",
    "weight vector for the model, the mean from all weight vectors is computed, and then used to segment our test set.\n",
    "Like this, the possible biases derived from different varibles like learning rate, epoch number or regularization\n",
    "factor can be avoided.\n",
    "\n",
    "# 8. Dice Coefficient\n",
    "## 8.1 The Theory behind the Dice Coefficient\n",
    "The dice coefficient is a score to evaluate and compare the accuracy of a segmentation.\n",
    "Needed for its calculation are the segmented image, as well as a corresponding binary reference point also called\n",
    "ground truth. (Bertels et al., 2019)\n",
    "Researchers mostly use the segmentation result of humans as ground truth image. We will use the ground truth images\n",
    "provided with the data sets, which we suspect to be generated by this method.\n",
    "Using the ground truth image, the labels true positive (TP), false positive (FP) and false\n",
    "negative (FN) are assigned to each pixel of the segmented image (Menze et al., 2015).\n",
    "This information is then used to calculate the dice coefficient using formula (1):"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\\begin{equation}\n",
    "(1) \\ dice = {\\frac{2TP}{2TP + FP + FN}} \\ \\ \\varepsilon \\ \\ [0,1]\n",
    "\\end{equation} <br>\n",
    "(Menze et al., 2015)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A dice score of 0 indicates that the ground truth and the segmentation result do not have any overlap. A dice score of 1 on the\n",
    "other hand, shows a 100% overlap of ground truth and segmented image (Bertels et al., 2019)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 8.2. Unittesting the Dice Coefficient\n",
    "To test the code for the dice coefficient, we used a frequently used method of software testing: unittests.\n",
    "Unittests are a way of validating that a specific code chunk, a unit, performs as expected and thus its result is as anticipated (Hamill, 2005).\n",
    "\n",
    "We implemented two kinds of unit tests.\n",
    "The dice coefficient of an image with itself is always 1.0. For our first unit test, we used this knowledge to test our code.\n",
    "For this first test we generated synthetic masks (see #6.2), black-and-white synthetic images, with which we performed the unit test.\n",
    "In addition, we compared our code's result to the python-implemented f1_score from sklearn.metrics. Both produced identical outputs.\n",
    "\n",
    "For the second unit test, we defined two random arrays, consisting only of ones and zeros.\n",
    "One array represented the segmented image, while the other served as ground truth.\n",
    "Using formula (1) we calculated the dice manually and compared our result with our codes' output.\n",
    "\n",
    "# 9. Results\n",
    "Our goal is to determine the optimal combination of different possible pre-processing methods to enhance\n",
    "the segmentation results of the original images. These methods encompass Gaussian filter, Watershed, Otsu thresholding and PCA.\n",
    "For a more precise evaluation, we use the dice score function to compare the final, segmented images.\n",
    "We compare with each other:\n",
    "•\timages without Pre-processing\n",
    "•\timages pre-processed with Gaussian filter\n",
    "•\timages pre-processed with Otsu thresholding\n",
    "•\timages pre-processed with Watershed\n",
    "•\timages pre-processed with PCA\n",
    "•\timages pre-processed with Gaussian filter and Otsu thresholding and Watershed.\n",
    "\n",
    "In the following, we aim to visualize the differences that pre-processing makes in our segmentation results.\n",
    "For that reason, the segementation result of t01 from the N2DH-GOWT1 dataset will be shown seven times. Each time a different\n",
    "pre-processing method from the list above was applied before the SVM.\n",
    "\n",
    "\n",
    "The following boxplots compare the Dice Scores of the different possible pre-processing methods each dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"Data/boxplots/boxplot_N2DH-GOW1-lr-1e-07.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this boxplot it becomes clear, that not using any features besides from pixel intensities gives the worst\n",
    "results, at least in terms of the highest variance in the dice scores.\n",
    "On the other hand, using all features gives a worse dice score mean, but its variance is much lower, so the images\n",
    "are better segmented all in all. The reduced mean can be explained because using many different features makes it\n",
    "harder for the SVM to find the minimum of the cost function, as there are many conditions to consider.\n",
    "In regard to\n",
    "the single filters, Gauss does not provide a great improvement from not applying a filter at all. Otsu provides a\n",
    "good dice score, and most importantly its variance is very small. Watershed, as expected, gives the best dice score\n",
    "mean, because it already segments the images, and so the SVM can get very valuable information from it. Lastly,\n",
    "because we use PCA to reduce our images to 95% variance. However, its values are probably highly correlated to\n",
    "the pixel intensities, which explains why the dice score mean from PCA is lower than no filter at all.\n",
    "\n",
    "*INSERT BOXPLOT DATA 2*\n",
    "\n",
    "From this boxplot we learn that\n",
    "\n",
    "*INSERT BOXPLOT DATA 3*\n",
    "\n",
    "This boxplot shows that\n",
    "\n",
    "We found that throughout all datasets the best setting is XXX.\n",
    "For N2DH-GOWT1 the best dice score is\n",
    "For N2DL-HeLa the best dice score is\n",
    "For NIH3T3 the best dice score is\n",
    "\n",
    "Nine synthetic images were created from each original image set using domain randomization, resulting in a total of 27 synthetic cell images.\n",
    "We used these images to enlarge each original image set during the SVMs training phase.\n",
    "The quality of the segmentation, measured by the Dice Score, stayed the same, when synthetic images were added to the training data set.\n",
    "We thus concluded, that they are as good as the original images in training the SVM.\n",
    "\n",
    "To be able to segement all of the original images, we therefore filled the training set with synthetic images only.\n",
    "This allowed us the put all original images into the validation set and thus made it possible to segment all of the original images.\n",
    "\n",
    "# 10. Discussion\n",
    "The SVM is a potent algorithm to segment images, as the dice scores proof. However, there are further issues that could\n",
    " be tackled in order to improve its segmentation capacities and obtain better results.\n",
    "\n",
    "First, we implemented a linear kernel to classify the data. In doing so, we supposed that the pixels can be linearly\n",
    "classified. We chose the linear kernel because we considered it the easiest and most effective one, runtime-wise,\n",
    "for our pixels. However, it is possible that they could be better classified using RBF, so this is an aspect that\n",
    "could be tested and implemented to improve the dice score.\n",
    "\n",
    "Secondly, we normalized and resized our data to reduce the number of pixels, in order to improve the runtime. In\n",
    "order to do so, we converted all images into squares, independently of their original dimensions. As a result, all\n",
    "our segmented images are squares. Although this process does not affect the quality of the segmentation, because\n",
    " the scaling affects both images and ground truths, it produces segmented images with dimensions that are not\n",
    " true to original. This is a minor issue that could be corrected in order to obtain images that are the same size\n",
    "  as the not segmented ones.\n",
    "\n",
    "Thirdly, we could add more features into the SVM, so that the machine learning algorithm has more information about\n",
    "every single pixel and can classify it better. Apart from the already implemented filters, we could use filters that\n",
    " give information about the edges, like Canny. Furthermore, it would be beneficial to insert information about the\n",
    " neighborhood of the pixel, so that the SVM can take into consideration the pixel intensities from neighboring pixels.\n",
    "\n",
    "Finally, PCA could be used for dimensionality reduction instead of as a feature, like we did. Like this, the images\n",
    "for the SVM would contain less pixels and therefore less information. Like this, we could investigate its impact on the\n",
    "runtime, which should be better, but the dice score would be less accurate.\n",
    "\n",
    "\n",
    "\n",
    "# 11. Bibliography\n",
    "\n",
    "Acal, C., Aguilera, A., Escabias, M. (2020). New Modeling Approaches Based on Varimax Rotation of Functional Principal Components\n",
    "\n",
    "Alghonaim, R., Johns, E. (2020).Benchmarking Domain Randomisation for Visual Sim-to-Real Transfer. CoRR.\n",
    "\n",
    "Berrar, D. (2019). Cross-validation. Data Science Laboratory, Tokyo Institute of Technology.\n",
    "\n",
    "Bertels, J., Eelbode, T., Berman, M., Vandermeulen D., Maes F., Bisschops, R., Blaschko, M. (2020).\n",
    "Optimization for Medical Image Segmentation: Theory and Practice when evaluating with Dice Score or Jaccard Index.\n",
    "IEEE Trans Med Imaging.\n",
    "\n",
    "Boser, B., Guyon, I., Vapnik, V. (1992). A training algorithm for optimal margin classifiers. Proceedings of the fifth\n",
    "annual workshop on Computational learning theory. Ed. 07.1992, 144–152.\n",
    "\n",
    "Burges, C. J. C. (1998). A Tutorial on Support Vector Machines for Pattern Recognition. Data Mining and Knowledge Discovery.\n",
    "\n",
    "Christianini, N., Ricci, E. (2008). Support Vector Machines. Encyclopedia of Algorithms, Springer.\n",
    "\n",
    "Deng, Guang & Cahill, L.W. (1993). An adaptive Gaussian filter for noise reduction and edge detection.\n",
    "Proc. of Nuclear Science Symposium and Medical Imaging Conference. 3. 1615 - 1619 vol.3.\n",
    "\n",
    "Dunn, K.W., Fu, C., Ho, D.J., Lee S., Han S., Salama P., Delp E. (2019). DeepSynth: Three-dimensional nuclear segmentation of\n",
    "biological images using neural networks trained with synthetic data. Nature.\n",
    "\n",
    "Evgeniou, T., Pontil, M. (2001). Support Vector Machines: Theory and Applications. Computer Science\n",
    "\n",
    "Evgeniou, T., Pontil, M., Poggio, T. (2000). Statistical Learning Theory: A Primer\n",
    "\n",
    "Friedrichs, F., Igel, C. (2005). Evolutionary tuning of multiple SVM parameters.\n",
    "\n",
    "Gedraite, E., Hadad, M. 2011. Investigation on the effect of a Gaussian Blur in image filtering and segmentation. 393-396.\n",
    "\n",
    "Geman, S., Bienenstock, E., Doursat, R. (1992). Neural Networks and the Bias/Variance Dilemma. Neural Computation.\n",
    "\n",
    "Guanasekaran, T., Shankar Kumar, K.R. (2010), Modified concentric circular micostrip array configurations for\n",
    "wimax base station. Journal of Theoretical and Applied Information Technology.\n",
    "\n",
    "Hamill, P. (2005). Unit Test Frameworks: Tools for High-Quality Software Development (S. 1 f.).\n",
    "\n",
    "Hegde, A., Principe, J., Erdogmus, D., Ozertem, U. (2006). Perturbation-Based Eigenvector Updates for On-Line Principal Components Analysis\n",
    "and Canonical Correlation Analysis. VLSI Signal Processing.\n",
    "\n",
    "Hsu, C., Chang, C., Lin C. (2016). A Practical Guide to Support Vector Classification. Department of Computer Science of the National Taiwan University.\n",
    "\n",
    "Jakkula, V. (2006). Tutorial on Support Vector Machine (SVM).\n",
    "\n",
    "Johnson, R., Zhang, T. (2013). Accelerating Stochastic Gradient Descent using Predictive Variance Reduction. 26th International\n",
    "Conference on Neural Information Processing Systems.\n",
    "\n",
    "Jolliffe, I. T., & Cadima, J. (2016). Principal component analysis: a review and recent developments. Philosophical transactions.\n",
    "Series A, Mathematical, physical, and engineering sciences, 374(2065).\n",
    "\n",
    "Keerthi, S. S., Lin, C. (2003). Asymptotic Behaviors of Support Vector Machines with Gaussian Kernel\n",
    "\n",
    "Khan, A. M., Ravi, S. (2013). Image Segmentation Methods: A Comparative Study. International Journal of Soft Computing\n",
    "and Engineering (IJSCE).\n",
    "\n",
    "Lever, J., Krzywinski, M., Altman, N. (2017). Principal component analysis. Nat Methods 14, 641–642.\n",
    "\n",
    "Mayer, N., Ilg, E., Fischer, P., Hazirbas, C., Cremers, D., Dosovitskiy, A.,Brox, T. (2018). What Makes Good Synthetic\n",
    "Training Data for Learning Disparity and Optical Flow Estimation?. Int J Comput Vis 126, 942–960.\n",
    "\n",
    "Mehta, B., Diaz, M., Golemo, F., Pal, C. J., Paull, L. (2020). Active Domain Randomization. Proceedings of Machine Learning Research.\n",
    "\n",
    "Menze, B., Jakab, A., Bauer, S., Kalpathy-Cramer, J., Farahani, K., Kirby, J., Burren, Y., Porz, N., Slotboom, J., Wiest, R., Lanczi, L.,\n",
    "Gerstner, E., Weber, M., Arbel, T., Avants, B., Ayache, N., Buendia, P., Collins, D., Cordier, N., Corso, J., Criminisi, A., Das, T.,\n",
    "Delingette, H., Demiralp, Ç., Durst, C., Dojat, M., Doyle, S., Festa, J., Forbes, F., Geremia, E., Glocker, B., Golland, P., Guo, X., Hamamci, A.,\n",
    "Iftekharuddin, K., Jena, R., John, N., Konukoglu, E., Lashkari, D., Mariz, J., Meier, R., Pereira, S., Precup, D., Price, S., Raviv, T.,\n",
    "Reza, S., Ryan, M., Sarikaya, D., Schwartz, L., Shin, H., Shotton, J., Silva, C., Sousa, N., Subbanna, N., Szekely, G., Taylor, T.,\n",
    "Thomas, O., Tustison, N., Unal, G., Vasseur, F., Wintermark, M., Ye, D., Zhao, L., Zhao, B., Zikic, D., Prastawa, M., Reyes, M., Van Leemput, K. (2015).\n",
    "The Multimodal Brain Tumor Image Segmentation Benchmark (BRATS). IEEE Trans Med Imaging.\n",
    "\n",
    "Rastar, A. (2019). A Novel Pixel-Averaging Technique for Extracting Training Data from a Single Image, Used in ML-Based Image Enlargement.\n",
    "\n",
    "Ruder, S. (2017). An overview of gradient descent optimization algorithms. Insight Centre for Data Analytics.\n",
    "\n",
    "Schüffler, P. J., Fuchs, T. J., Ong, C. S., Wild, P. J., Rupp, N. J., Buhmann, J. M. 2013. TMARKER: A free software\n",
    "toolkit for histopathological cell counting and staining estimation. Journal of Pathology Informatics.\n",
    "\n",
    "Suthaharan S. (2016). Support Vector Machine. Machine Learning Models and Algorithms for Big Data Classification.\n",
    "Integrated Series in Information Systems, vol 36. Springer.\n",
    "\n",
    "Thai, L.H., Tran S.H., Nguyen T.T. (2012). Image Classification using Support Vector Machine and Artificial Neural Network.\n",
    "International Journal of Information Technology and Computer Science (IJITCS).\n",
    "\n",
    "Tripathi, S., Chandra S., Agrawal, A., Tyagi, A., Rehg, J. M., Chari, V. (2019). Learning to Generate Synthetic\n",
    "Data via Compositing. IEEE Xplore.\n",
    "\n",
    "Vabalas, A., Gowen, E., Poliakoff, E., Casson, A.J. (2019). Machine learning algorithm validation with a limited sample size. Plos one.\n",
    "\n",
    "Veta, M., van Diest, P. J., Kornegoor, R., Huisman, A., Viergever, M. A., Pluim, J. P. W. (2013). Automatic Nuclei\n",
    "Segmentation in H&E Stained Breast Cancer Histopathology Images. Plos one.\n",
    "\n",
    "Ward, D.,Moghadam P.,Hudson, N. (2019). Deep Leaf Segmentation Using Synthetic Data. CoRR.\n",
    "\n",
    "Yang, Z., Yu, Y., You, Y., Steinhardt, J., Ma, Y. (2020). Rethinking Bias-Variance Trade-off\n",
    "for Generalization of Neural Networks. Cornell University.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}